{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Emotion detection from text is an important task in natural language processing (NLP) that helps machines understand human feelings expressed through written language.\n",
        "\n",
        "By fine-tuning pretrained transformer models like DistilBERT on labeled emotion datasets, I build a classifier that automatically identify emotions such as sadness, joy, anger, and fear from sentences.\n",
        "\n",
        "This technology has real-world applications across many fields.\n",
        "\n",
        "1. In customer service, emotion detection enables chatbots and support agents to respond empathetically to frustrated or happy customers.\n",
        "\n",
        "2. In social media monitoring, it helps companies gauge public sentiment about products or events.\n",
        "\n",
        "3. Mental health platforms use emotion recognition to monitor usersâ€™ emotional wellbeing and provide timely support.\n",
        "\n",
        "4. Emotion detection is useful in marketing, content recommendation, and even human-computer interaction to create more personalized experiences.\n",
        "\n",
        "In this notebook, I fine-tuned a transformer model for emotion classification, evaluated its performance, and tested it on various sample sentences."
      ],
      "metadata": {
        "id": "1yDeGs0fe3Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations"
      ],
      "metadata": {
        "id": "vFyt1cmE8dus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Wm_nXX8cxG"
      },
      "outputs": [],
      "source": [
        "# installs or updates the required librarires and dependencies\n",
        "!pip install --quiet --upgrade transformers datasets huggingface_hub bertviz gcsfs fsspec umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "5fPyuLSh8-yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import list_datasets\n",
        "from transformers import AutoModelForSequenceClassification, \\\n",
        "AutoTokenizer, Trainer, TrainingArguments, pipeline\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "l6Pnx2IJ87-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "Osnazg0P-oLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_dataset = load_dataset(\"dair-ai/emotion\")"
      ],
      "metadata": {
        "id": "fzBpiBft-XJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_dataset"
      ],
      "metadata": {
        "id": "xlKuDfRu_OLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing & EDA"
      ],
      "metadata": {
        "id": "70g0-167B-_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_dataset.set_format(type = 'pandas')"
      ],
      "metadata": {
        "id": "p2tPFVCZ_UlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = emotions_dataset['train'][:]"
      ],
      "metadata": {
        "id": "laniYSWJ_aO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "eO7Vcrph_dRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = emotions_dataset['train'].features['label'].names\n",
        "classes"
      ],
      "metadata": {
        "id": "r_4akBnd_lpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying class names\n",
        "df_train['label_name'] = df_train['label'].apply(lambda x: classes[x])"
      ],
      "metadata": {
        "id": "f7FVGuVu_t4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "V0pEEFCzAEyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counts\n",
        "label_name_counts = df_train['label_name'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "# Horizontal bar graph\n",
        "label_name_counts.plot(kind='barh', figsize=(8,5))\n",
        "plt.title('Count of Each Label Name')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Label Name')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vII0DfM7AHtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count words per tweet\n",
        "df_train[\"Words per tweet\"] = df_train['text'].str.split().apply(len)"
      ],
      "metadata": {
        "id": "51iLgqr6ASQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(2)"
      ],
      "metadata": {
        "id": "S6B6e9TmBkck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot showing distribution of words in the dataset\n",
        "sns.boxplot(data=df_train, y='label_name', x ='Words per tweet')\n",
        "plt.title(\"Distribution of Words Per tweet\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KG2Y86c5AvKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Model"
      ],
      "metadata": {
        "id": "Td7C_iwhCs8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'distilbert/distilbert-base-uncased'"
      ],
      "metadata": {
        "id": "YRzudESUC1M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "8PPVyjI1Cg9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "tbUJNfTUELrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'I am finetuning a transformer model'\n",
        "encoded_text = tokenizer(text)\n",
        "encoded_text"
      ],
      "metadata": {
        "id": "mvrqiSC2BLb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_dataset.reset_format()"
      ],
      "metadata": {
        "id": "hpLZ30qnEWgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing(batch):\n",
        "  temp = tokenizer(batch['text'], padding=True, truncation=True)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "nCbDICgoEi9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tonizing the train data\n",
        "tokenizing(emotions_dataset['train'][:1])"
      ],
      "metadata": {
        "id": "PjzqdMkdEsRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing train, eval and test datasets\n",
        "emotions_encoded = emotions_dataset.map(tokenizing, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "BpbxvadsFQJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded, emotions_dataset"
      ],
      "metadata": {
        "id": "DNa6RU-RGF4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning Process"
      ],
      "metadata": {
        "id": "euEykFefGoGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# loading model, adding output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "id": "o_rxNcpiIFZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Arguments\n",
        "batch_size = 62\n",
        "model_name = 'distiled-bert-finedtuned-emotions'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_name,\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    num_train_epochs = 2,\n",
        "    weight_decay = 0.01,\n",
        "    eval_strategy = 'epoch',\n",
        "    disable_tqdm = False\n",
        ")"
      ],
      "metadata": {
        "id": "a9-tHkyfLBqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates how well the model is performing after every epoch\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids  # true labels\n",
        "  preds = pred.predictions.argmax(-1) # predicted labels, retruns index of the highest score\n",
        "  f1 = f1_score(labels, preds, average = 'weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'f1': f1}"
      ],
      "metadata": {
        "id": "mAXLfVQ6MzhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model trainer\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset = emotions_encoded['train'],\n",
        "    eval_dataset = emotions_encoded['validation'],\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "JV9e4e-OM3Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "SCKo5y34OyV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Model Performance"
      ],
      "metadata": {
        "id": "i6Se060WTqaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract eval_loss and eval_accuracy from logs\n",
        "eval_losses = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "eval_accuracies = [log['eval_accuracy'] for log in trainer.state.log_history if 'eval_accuracy' in log]\n",
        "\n",
        "print(eval_losses)\n",
        "print(eval_accuracies)\n"
      ],
      "metadata": {
        "id": "V0Yk4qeoR39J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_outputs = trainer.predict(emotions_encoded['test'])\n",
        "preds_outputs.metrics"
      ],
      "metadata": {
        "id": "3A5mdhkxSK5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_labels = np.argmax(preds_outputs.predictions, axis=1)"
      ],
      "metadata": {
        "id": "BjzTobzhT17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded"
      ],
      "metadata": {
        "id": "kozxjbNFWi_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_labels = emotions_encoded['test'][:]['label']"
      ],
      "metadata": {
        "id": "BzIvsQ0SWWlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predicted_labels[:5])\n",
        "print(y_true_labels[:5])"
      ],
      "metadata": {
        "id": "G5kGfL0mUCcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)\n",
        "print()\n",
        "\n",
        "# Classification Report\n",
        "cr = classification_report(y_true_labels, y_predicted_labels)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "DiVL5UfwW5xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_labels, y_predicted_labels)\n",
        "\n",
        "# Visulizing\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q_O4DxvQXbyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(text):\n",
        "  # tokenize input\n",
        "  inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "  # Send inputs to same device as model\n",
        "  inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "  # Get raw logits from the model\n",
        "  with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "\n",
        "  logits = outputs.logits  # Extracts logits from the ouput\n",
        "\n",
        "  predicted_index = np.argmax(logits.cpu().numpy(), axis=1)[0] # moves logits to cpu, converts it to numpy array, returns index with highest score\n",
        "\n",
        "  return classes[predicted_index]"
      ],
      "metadata": {
        "id": "QKIdsOLcX27F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_emotion(\"She surprised me with a birthday party I didnâ€™t expect!\")"
      ],
      "metadata": {
        "id": "-5bXVS4pavuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"I can't stop thinking about how everything could go wrong.\",\n",
        "    \"I feel completely drained even though nothing major happened today.\",\n",
        "    \"There's a strange calmness in me even though I know I should be worried.\",\n",
        "    \"I'm happy for my friend, but I can't help feeling a little jealous too.\",\n",
        "    \"I feel a deep sense of peace after confronting my fears.\",\n",
        "    \"I'm frustrated because I know I can do better, but something holds me back.\",\n",
        "    \"Iâ€™m excited about the opportunity, but the pressure is overwhelming.\",\n",
        "    \"I feel guilty for being happy while others are suffering.\",\n",
        "    \"I miss how things used to be â€” thereâ€™s a constant ache in my chest.\",\n",
        "    \"Even in a room full of people, I feel invisible.\"\n",
        "]"
      ],
      "metadata": {
        "id": "9OtK4PhDay8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions on text sentences\n",
        "for sentence in test_sentences:\n",
        "  prediction = predict_emotion(sentence)\n",
        "  print(f\"Sentence: {sentence}\\nPredicted Emotion: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "LjSwNVKydWdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}